{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "PIXELS = 1024\n",
    "DIMENSIONS = np.int16(math.sqrt(PIXELS))\n",
    "\n",
    "TRAINING_FEATURES_FILE = \"csvTrainImages 13440x1024.csv\"\n",
    "TRAINING_LABELS_FILE = \"csvTrainLabel 13440x1.csv\"\n",
    "TESTING_FEATURES_FILE = \"csvTestImages 3360x1024.csv\"\n",
    "TESTING_LABELS_FILE = \"csvTestLabel 3360x1.csv\"\n",
    "\n",
    "def load_data(file=TRAINING_FEATURES_FILE, header=True):\n",
    "    csv_path = os.path.join(\"dataset/\", file)\n",
    "    if header:\n",
    "        return pd.read_csv(csv_path)\n",
    "    else:\n",
    "        return pd.read_csv(csv_path, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.9</th>\n",
       "      <th>...</th>\n",
       "      <th>0.896</th>\n",
       "      <th>0.897</th>\n",
       "      <th>0.898</th>\n",
       "      <th>0.899</th>\n",
       "      <th>0.900</th>\n",
       "      <th>0.901</th>\n",
       "      <th>0.902</th>\n",
       "      <th>0.903</th>\n",
       "      <th>0.904</th>\n",
       "      <th>0.905</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1024 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  ...    0.896  0.897  0.898  \\\n",
       "0  0    0    0    0    0    0    0    0    0    0  ...        0      0      0   \n",
       "1  0    0    0    0    0    0    0    0    0    0  ...        0      0      0   \n",
       "2  0    0    0    0    0    0    0    0    0    0  ...        0      0      0   \n",
       "3  0    0    0    0    0    0    0    0    0    0  ...        0      0      0   \n",
       "4  0    0    0    0    0    0    0    0    0    0  ...        0      0      0   \n",
       "\n",
       "   0.899  0.900  0.901  0.902  0.903  0.904  0.905  \n",
       "0      0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0      0  \n",
       "3      0      0      0      0      0      0      0  \n",
       "4      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 1024 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_data(TRAINING_FEATURES_FILE)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def imagify(arr, getimage=False, showimage=True):\n",
    "    img = np.array(np.reshape(arr, (DIMENSIONS, DIMENSIONS)), dtype=\"uint8\")\n",
    "    if showimage:\n",
    "        plt.imshow(img, interpolation='nearest')\n",
    "        plt.gray()\n",
    "        plt.show() \n",
    "        \n",
    "    if getimage:\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showimage(img):\n",
    "    plt.imshow(img, interpolation='nearest')\n",
    "    plt.gray()\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x120c83588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = imagify(data.values[7], getimage=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "th1,img1 = cv2.threshold(img,127,255,cv2.THRESH_BINARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x120c13748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(th1)\n",
    "showimage(img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "th2,img2 = cv2.threshold(img,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x120c44240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(th2)\n",
    "showimage(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "blur = cv2.GaussianBlur(img,(5,5),0)\n",
    "th3,img3 = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1204b76a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(th3)\n",
    "showimage(img3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESH_BINARY = cv2.THRESH_BINARY\n",
    "THRESH_BINARY_AND_THRESH_OTSU = cv2.THRESH_BINARY+cv2.THRESH_OTSU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_thresholding(df, cap=0, thres=THRESH_BINARY_AND_THRESH_OTSU):\n",
    "    if thres == None:\n",
    "        return df\n",
    "    \n",
    "    values = df.values\n",
    "    thres_values = []\n",
    "    thresholding_started = False\n",
    "    for value in values:\n",
    "        img = imagify(value, getimage=True, showimage=False)\n",
    "        th_,img = cv2.threshold(img,cap,255,thres)\n",
    "        img = [img.flatten()]\n",
    "        if thresholding_started:\n",
    "            thres_values = np.concatenate((thres_values, img), axis=0)\n",
    "        else:\n",
    "            thres_values = img\n",
    "            thresholding_started = True\n",
    "            \n",
    "    thres_df = pd.DataFrame(thres_values, columns=df.columns)\n",
    "    return thres_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.9</th>\n",
       "      <th>...</th>\n",
       "      <th>0.896</th>\n",
       "      <th>0.897</th>\n",
       "      <th>0.898</th>\n",
       "      <th>0.899</th>\n",
       "      <th>0.900</th>\n",
       "      <th>0.901</th>\n",
       "      <th>0.902</th>\n",
       "      <th>0.903</th>\n",
       "      <th>0.904</th>\n",
       "      <th>0.905</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1024 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  ...    0.896  0.897  0.898  \\\n",
       "0  0    0    0    0    0    0    0    0    0    0  ...        0      0      0   \n",
       "1  0    0    0    0    0    0    0    0    0    0  ...        0      0      0   \n",
       "2  0    0    0    0    0    0    0    0    0    0  ...        0      0      0   \n",
       "3  0    0    0    0    0    0    0    0    0    0  ...        0      0      0   \n",
       "4  0    0    0    0    0    0    0    0    0    0  ...        0      0      0   \n",
       "\n",
       "   0.899  0.900  0.901  0.902  0.903  0.904  0.905  \n",
       "0      0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0      0  \n",
       "3      0      0      0      0      0      0      0  \n",
       "4      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 1024 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datacopy = data.copy()\n",
    "data = apply_thresholding(data, thres=THRESH_BINARY_AND_THRESH_OTSU)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "def get_dims_variances(x, min_dim, max_dim, threshold=0.1, capToThreshold=False):\n",
    "    dims = []\n",
    "    variances = []\n",
    "    optimum_dim = min_dim\n",
    "    saturation_reached = False\n",
    "    for dim in range(min_dim, max_dim + 1):\n",
    "        pca = PCA(n_components=dim)\n",
    "        pca.fit(x)\n",
    "        variance = np.array(pca.explained_variance_ratio_)\n",
    "        variance = variance.min()\n",
    "        if threshold < variance:\n",
    "            optimum_dim = dim\n",
    "        else:\n",
    "            saturation_reached = True\n",
    "        \n",
    "        if saturation_reached and capToThreshold:\n",
    "            break\n",
    "        else:    \n",
    "            dims.append(dim)\n",
    "            variances.append(variance)\n",
    "        \n",
    "    return dims, variances, optimum_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "#dims, variances, OPTIMUM_DIMENSION = get_dims_variances(data, 2, 100, 0.005, capToThreshold=True)\n",
    "OPTIMUM_DIMENSION = 36\n",
    "print(OPTIMUM_DIMENSION)\n",
    "import matplotlib.pyplot as plt\n",
    "#plt.plot(dims, variances)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dim_var = pd.DataFrame()\n",
    "#dim_var[\"DIM\"] = dims\n",
    "#dim_var[\"VAR\"] = variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=OPTIMUM_DIMENSION)\n",
    "training_features = pca.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "imputer = Imputer(strategy=\"median\")\n",
    "training_features = imputer.fit_transform(training_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scalar = StandardScaler()\n",
    "training_features = scalar.fit_transform(training_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_labels = load_data(TRAINING_LABELS_FILE)\n",
    "training_labels = data_labels.values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = load_data(TESTING_FEATURES_FILE)\n",
    "test_data = apply_thresholding(test_data, thres=THRESH_BINARY_AND_THRESH_OTSU)\n",
    "testing_features = pca.transform(test_data)\n",
    "testing_features = imputer.transform(testing_features)\n",
    "testing_features = scalar.transform(testing_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_labels = load_data(TESTING_LABELS_FILE)\n",
    "testing_labels = test_data_labels.values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Val Scores on training set\n",
      " [0.20558036 0.18504464 0.22705961]\n",
      "\n",
      "\n",
      "Accuracy on testing data set\n",
      " 0.2232807383149747\n"
     ]
    }
   ],
   "source": [
    "# SGD Classifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.base import clone\n",
    "\n",
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "print(\"Cross Val Scores on training set\\n\", cross_val_score(clone(sgd_clf), training_features, training_labels, cv=3, scoring=\"accuracy\"))\n",
    "\n",
    "\n",
    "sgd_clf.fit(training_features, training_labels)\n",
    "print(\"\\n\\nAccuracy on testing data set\\n\", sum(testing_labels == sgd_clf.predict(testing_features)) / len(testing_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Val Scores on training set\n",
      " [0.36272321 0.36116071 0.40477785]\n",
      "\n",
      "\n",
      "Accuracy on testing data set\n",
      " 0.515034236379875\n"
     ]
    }
   ],
   "source": [
    "# KNeighbors Classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "\n",
    "knn_clf = KNeighborsClassifier()\n",
    "print(\"Cross Val Scores on training set\\n\", cross_val_score(clone(knn_clf), training_features, training_labels, cv=3, scoring=\"accuracy\"))\n",
    "\n",
    "knn_clf.fit(training_features, training_labels)\n",
    "print(\"\\n\\nAccuracy on testing data set\\n\", sum(testing_labels == knn_clf.predict(testing_features)) / len(testing_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Val Scores on training set\n",
      " [0.29955357 0.30513393 0.32395624]\n",
      "\n",
      "\n",
      "Accuracy on testing data set\n",
      " 0.414409050312593\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "forest_clf = RandomForestClassifier(random_state=42)\n",
    "print(\"Cross Val Scores on training set\\n\", cross_val_score(clone(forest_clf), training_features, training_labels, cv=3, scoring=\"accuracy\"))\n",
    "\n",
    "forest_clf.fit(training_features, training_labels)\n",
    "print(\"\\n\\nAccuracy on testing data set\\n\", sum(testing_labels == forest_clf.predict(testing_features)) / len(testing_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 1024)              37888     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 28)                28700     \n",
      "=================================================================\n",
      "Total params: 1,116,188\n",
      "Trainable params: 1,116,188\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13439 samples, validate on 3359 samples\n",
      "Epoch 1/30\n",
      "13439/13439 [==============================] - 3s 221us/step - loss: 2.3070 - acc: 0.3078 - val_loss: 1.7271 - val_acc: 0.4370\n",
      "Epoch 2/30\n",
      "13439/13439 [==============================] - 2s 178us/step - loss: 1.6235 - acc: 0.4682 - val_loss: 1.3343 - val_acc: 0.5609\n",
      "Epoch 3/30\n",
      "13439/13439 [==============================] - 2s 171us/step - loss: 1.3234 - acc: 0.5520 - val_loss: 1.1171 - val_acc: 0.6267\n",
      "Epoch 4/30\n",
      "13439/13439 [==============================] - 2s 169us/step - loss: 1.1433 - acc: 0.6098 - val_loss: 1.0375 - val_acc: 0.6314\n",
      "Epoch 5/30\n",
      "13439/13439 [==============================] - 2s 171us/step - loss: 1.0288 - acc: 0.6407 - val_loss: 0.9446 - val_acc: 0.6689\n",
      "Epoch 6/30\n",
      "13439/13439 [==============================] - 3s 196us/step - loss: 0.9304 - acc: 0.6681 - val_loss: 0.9052 - val_acc: 0.6782\n",
      "Epoch 7/30\n",
      "13439/13439 [==============================] - 3s 193us/step - loss: 0.8647 - acc: 0.6942 - val_loss: 0.8600 - val_acc: 0.6844\n",
      "Epoch 8/30\n",
      "13439/13439 [==============================] - 3s 197us/step - loss: 0.8100 - acc: 0.7140 - val_loss: 0.8452 - val_acc: 0.6963\n",
      "Epoch 9/30\n",
      "13439/13439 [==============================] - 3s 200us/step - loss: 0.7476 - acc: 0.7335 - val_loss: 0.8124 - val_acc: 0.7115\n",
      "Epoch 10/30\n",
      "13439/13439 [==============================] - 3s 197us/step - loss: 0.6957 - acc: 0.7477 - val_loss: 0.7986 - val_acc: 0.7148\n",
      "Epoch 11/30\n",
      "13439/13439 [==============================] - 3s 196us/step - loss: 0.6587 - acc: 0.7612 - val_loss: 0.7638 - val_acc: 0.7341\n",
      "Epoch 12/30\n",
      "13439/13439 [==============================] - 3s 195us/step - loss: 0.6240 - acc: 0.7749 - val_loss: 0.7550 - val_acc: 0.7294\n",
      "Epoch 13/30\n",
      "13439/13439 [==============================] - 3s 199us/step - loss: 0.5836 - acc: 0.7895 - val_loss: 0.7404 - val_acc: 0.7419\n",
      "Epoch 14/30\n",
      "13439/13439 [==============================] - 3s 198us/step - loss: 0.5505 - acc: 0.7989 - val_loss: 0.7558 - val_acc: 0.7389\n",
      "Epoch 15/30\n",
      "13439/13439 [==============================] - 3s 197us/step - loss: 0.5151 - acc: 0.8112 - val_loss: 0.7378 - val_acc: 0.7446\n",
      "Epoch 16/30\n",
      "13439/13439 [==============================] - 3s 196us/step - loss: 0.5121 - acc: 0.8142 - val_loss: 0.7271 - val_acc: 0.7484\n",
      "Epoch 17/30\n",
      "13439/13439 [==============================] - 3s 200us/step - loss: 0.4745 - acc: 0.8289 - val_loss: 0.7504 - val_acc: 0.7431\n",
      "Epoch 18/30\n",
      "13439/13439 [==============================] - 3s 197us/step - loss: 0.4361 - acc: 0.8393 - val_loss: 0.7266 - val_acc: 0.7511\n",
      "Epoch 19/30\n",
      "13439/13439 [==============================] - 3s 203us/step - loss: 0.4190 - acc: 0.8501 - val_loss: 0.7478 - val_acc: 0.7490\n",
      "Epoch 20/30\n",
      "13439/13439 [==============================] - 3s 200us/step - loss: 0.4051 - acc: 0.8503 - val_loss: 0.7303 - val_acc: 0.7595\n",
      "Epoch 21/30\n",
      "13439/13439 [==============================] - 3s 202us/step - loss: 0.3822 - acc: 0.8612 - val_loss: 0.7356 - val_acc: 0.7541\n",
      "Epoch 22/30\n",
      "13439/13439 [==============================] - 3s 204us/step - loss: 0.3757 - acc: 0.8637 - val_loss: 0.7336 - val_acc: 0.7565\n",
      "Epoch 23/30\n",
      "13439/13439 [==============================] - 3s 202us/step - loss: 0.3445 - acc: 0.8800 - val_loss: 0.7424 - val_acc: 0.7612\n",
      "Epoch 24/30\n",
      "13439/13439 [==============================] - 3s 197us/step - loss: 0.3284 - acc: 0.8806 - val_loss: 0.7535 - val_acc: 0.7526\n",
      "Epoch 25/30\n",
      "13439/13439 [==============================] - 3s 204us/step - loss: 0.3202 - acc: 0.8815 - val_loss: 0.7687 - val_acc: 0.7526\n",
      "Epoch 26/30\n",
      "13439/13439 [==============================] - 3s 199us/step - loss: 0.3156 - acc: 0.8859 - val_loss: 0.7622 - val_acc: 0.7556\n",
      "Epoch 27/30\n",
      "13439/13439 [==============================] - 3s 196us/step - loss: 0.2983 - acc: 0.8949 - val_loss: 0.7529 - val_acc: 0.7592\n",
      "Epoch 28/30\n",
      "13439/13439 [==============================] - 3s 196us/step - loss: 0.2812 - acc: 0.8960 - val_loss: 0.7711 - val_acc: 0.7556\n",
      "Epoch 29/30\n",
      "13439/13439 [==============================] - 3s 201us/step - loss: 0.2721 - acc: 0.9019 - val_loss: 0.7659 - val_acc: 0.7633\n",
      "Epoch 30/30\n",
      "13439/13439 [==============================] - 3s 199us/step - loss: 0.2674 - acc: 0.9028 - val_loss: 0.7741 - val_acc: 0.7618\n",
      "3359/3359 [==============================] - 0s 85us/step\n",
      "Test loss: 0.7740838663781743\n",
      "Test accuracy: 0.7618338792194175\n"
     ]
    }
   ],
   "source": [
    "# MLP Classifier\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 28\n",
    "epochs = 30\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, activation='relu', input_shape=(OPTIMUM_DIMENSION,)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "adam = Adam()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "binarizer = LabelBinarizer()\n",
    "binarizer.fit(training_labels)\n",
    "training_labels = binarizer.transform(training_labels)\n",
    "testing_labels = binarizer.transform(testing_labels)\n",
    "\n",
    "history = model.fit(training_features, training_labels,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(testing_features, testing_labels))\n",
    "\n",
    "score = model.evaluate(testing_features, testing_labels, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 256)         2560      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 2, 2, 256)         590080    \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 28)                28700     \n",
      "=================================================================\n",
      "Total params: 2,720,540\n",
      "Trainable params: 2,720,540\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13439 samples, validate on 3359 samples\n",
      "Epoch 1/30\n",
      "13439/13439 [==============================] - 14s 1ms/step - loss: 2.4049 - acc: 0.2607 - val_loss: 1.6239 - val_acc: 0.4332\n",
      "Epoch 2/30\n",
      "13439/13439 [==============================] - 14s 1ms/step - loss: 1.4662 - acc: 0.4913 - val_loss: 1.2633 - val_acc: 0.5457\n",
      "Epoch 3/30\n",
      "13439/13439 [==============================] - 14s 1ms/step - loss: 1.1801 - acc: 0.5758 - val_loss: 1.1096 - val_acc: 0.6011\n",
      "Epoch 4/30\n",
      "13439/13439 [==============================] - 14s 1ms/step - loss: 0.9919 - acc: 0.6362 - val_loss: 0.9957 - val_acc: 0.6460\n",
      "Epoch 5/30\n",
      "13439/13439 [==============================] - 14s 1ms/step - loss: 0.8521 - acc: 0.6818 - val_loss: 0.9802 - val_acc: 0.6475\n",
      "Epoch 6/30\n",
      "13439/13439 [==============================] - 14s 1ms/step - loss: 0.7485 - acc: 0.7172 - val_loss: 0.9391 - val_acc: 0.6630\n",
      "Epoch 7/30\n",
      "13439/13439 [==============================] - 14s 1ms/step - loss: 0.6598 - acc: 0.7523 - val_loss: 0.9550 - val_acc: 0.6651\n",
      "Epoch 8/30\n",
      "13439/13439 [==============================] - 14s 1ms/step - loss: 0.5888 - acc: 0.7690 - val_loss: 0.9546 - val_acc: 0.6844\n",
      "Epoch 9/30\n",
      "13439/13439 [==============================] - 14s 1ms/step - loss: 0.5145 - acc: 0.8015 - val_loss: 0.9414 - val_acc: 0.6865\n",
      "Epoch 10/30\n",
      "13439/13439 [==============================] - 14s 1ms/step - loss: 0.4691 - acc: 0.8216 - val_loss: 0.9715 - val_acc: 0.6794\n",
      "Epoch 11/30\n",
      "13439/13439 [==============================] - 14s 1ms/step - loss: 0.4188 - acc: 0.8377 - val_loss: 0.9982 - val_acc: 0.6889\n",
      "Epoch 12/30\n",
      "13439/13439 [==============================] - 14s 1ms/step - loss: 0.3784 - acc: 0.8557 - val_loss: 1.0079 - val_acc: 0.6889\n",
      "Epoch 13/30\n",
      "13439/13439 [==============================] - 13s 955us/step - loss: 0.3518 - acc: 0.8683 - val_loss: 1.0149 - val_acc: 0.7023\n",
      "Epoch 14/30\n",
      "13439/13439 [==============================] - 12s 856us/step - loss: 0.3336 - acc: 0.8759 - val_loss: 1.0307 - val_acc: 0.7005\n",
      "Epoch 15/30\n",
      "13439/13439 [==============================] - 12s 871us/step - loss: 0.2966 - acc: 0.8894 - val_loss: 1.0993 - val_acc: 0.6832\n",
      "Epoch 16/30\n",
      "13439/13439 [==============================] - 11s 827us/step - loss: 0.2837 - acc: 0.8945 - val_loss: 1.2464 - val_acc: 0.6785\n",
      "Epoch 17/30\n",
      "13439/13439 [==============================] - 12s 893us/step - loss: 0.2563 - acc: 0.9054 - val_loss: 1.1401 - val_acc: 0.6966\n",
      "Epoch 18/30\n",
      "13439/13439 [==============================] - 11s 849us/step - loss: 0.2414 - acc: 0.9149 - val_loss: 1.0984 - val_acc: 0.7103\n",
      "Epoch 19/30\n",
      "13439/13439 [==============================] - 12s 874us/step - loss: 0.2293 - acc: 0.9157 - val_loss: 1.1458 - val_acc: 0.7035\n",
      "Epoch 20/30\n",
      "13439/13439 [==============================] - 12s 868us/step - loss: 0.1957 - acc: 0.9291 - val_loss: 1.2497 - val_acc: 0.7047\n",
      "Epoch 21/30\n",
      "13439/13439 [==============================] - 11s 839us/step - loss: 0.2091 - acc: 0.9237 - val_loss: 1.2722 - val_acc: 0.6978\n",
      "Epoch 22/30\n",
      "13439/13439 [==============================] - 11s 844us/step - loss: 0.2100 - acc: 0.9276 - val_loss: 1.2431 - val_acc: 0.6996\n",
      "Epoch 23/30\n",
      "13439/13439 [==============================] - 12s 860us/step - loss: 0.1718 - acc: 0.9383 - val_loss: 1.3092 - val_acc: 0.6972\n",
      "Epoch 24/30\n",
      "13439/13439 [==============================] - 12s 870us/step - loss: 0.1787 - acc: 0.9391 - val_loss: 1.2889 - val_acc: 0.6963\n",
      "Epoch 25/30\n",
      "13439/13439 [==============================] - 11s 855us/step - loss: 0.1703 - acc: 0.9384 - val_loss: 1.3556 - val_acc: 0.7011\n",
      "Epoch 26/30\n",
      "13439/13439 [==============================] - 12s 899us/step - loss: 0.1664 - acc: 0.9410 - val_loss: 1.3477 - val_acc: 0.7023\n",
      "Epoch 27/30\n",
      "13439/13439 [==============================] - 11s 840us/step - loss: 0.1500 - acc: 0.9473 - val_loss: 1.3949 - val_acc: 0.6871\n",
      "Epoch 28/30\n",
      "13439/13439 [==============================] - 11s 843us/step - loss: 0.1591 - acc: 0.9440 - val_loss: 1.3661 - val_acc: 0.7050\n",
      "Epoch 29/30\n",
      "13439/13439 [==============================] - 13s 1ms/step - loss: 0.1590 - acc: 0.9454 - val_loss: 1.4421 - val_acc: 0.6931\n",
      "Epoch 30/30\n",
      "13439/13439 [==============================] - 14s 1ms/step - loss: 0.1440 - acc: 0.9505 - val_loss: 1.4132 - val_acc: 0.7023\n",
      "3359/3359 [==============================] - 0s 132us/step\n",
      "Test loss: 1.4132200933773271\n",
      "Test accuracy: 0.7022923487359195\n"
     ]
    }
   ],
   "source": [
    "# CNN Classifier\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 28\n",
    "epochs = 30\n",
    "size = np.int16(math.sqrt(OPTIMUM_DIMENSION))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(256, kernel_size=(3, 3), strides=(1, 1),\n",
    "                 activation='relu',\n",
    "                 input_shape=(size, size, 1)))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Conv2D(256, kernel_size=(3, 3), strides=(1, 1), activation='relu'))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "adam = Adam()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "training_features = np.reshape(training_features, (-1, size, size, 1))\n",
    "testing_features = np.reshape(testing_features, (-1, size, size, 1))\n",
    "\n",
    "binarizer = LabelBinarizer()\n",
    "binarizer.fit(training_labels)\n",
    "training_labels = binarizer.transform(training_labels)\n",
    "testing_labels = binarizer.transform(testing_labels)\n",
    "\n",
    "history = model.fit(training_features, training_labels,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(testing_features, testing_labels))\n",
    "\n",
    "score = model.evaluate(testing_features, testing_labels, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
