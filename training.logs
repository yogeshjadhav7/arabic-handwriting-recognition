Using TensorFlow backend.
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 31, 31, 256)       1280      
_________________________________________________________________
batch_normalization_1 (Batch (None, 31, 31, 256)       1024      
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 28, 28, 256)       1048832   
_________________________________________________________________
batch_normalization_2 (Batch (None, 28, 28, 256)       1024      
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 14, 14, 256)       0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 11, 11, 256)       1048832   
_________________________________________________________________
batch_normalization_3 (Batch (None, 11, 11, 256)       1024      
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 8, 8, 256)         1048832   
_________________________________________________________________
batch_normalization_4 (Batch (None, 8, 8, 256)         1024      
_________________________________________________________________
dropout_1 (Dropout)          (None, 8, 8, 256)         0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 16384)             0         
_________________________________________________________________
dense_1 (Dense)              (None, 512)               8389120   
_________________________________________________________________
batch_normalization_5 (Batch (None, 512)               2048      
_________________________________________________________________
dropout_2 (Dropout)          (None, 512)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 256)               131328    
_________________________________________________________________
batch_normalization_6 (Batch (None, 256)               1024      
_________________________________________________________________
dropout_3 (Dropout)          (None, 256)               0         
_________________________________________________________________
dense_3 (Dense)              (None, 128)               32896     
_________________________________________________________________
batch_normalization_7 (Batch (None, 128)               512       
_________________________________________________________________
dropout_4 (Dropout)          (None, 128)               0         
_________________________________________________________________
dense_4 (Dense)              (None, 28)                3612      
=================================================================
Total params: 11,712,412
Trainable params: 11,708,572
Non-trainable params: 3,840
_________________________________________________________________

Epoch 00001: val_acc improved from -inf to 0.52248, saving model to trained_model.h5

Epoch 00002: val_acc did not improve

Epoch 00003: val_acc improved from 0.52248 to 0.55761, saving model to trained_model.h5

Epoch 00004: val_acc improved from 0.55761 to 0.71896, saving model to trained_model.h5

Epoch 00005: val_acc improved from 0.71896 to 0.77642, saving model to trained_model.h5

Epoch 00006: val_acc improved from 0.77642 to 0.84311, saving model to trained_model.h5

Epoch 00007: val_acc improved from 0.84311 to 0.90205, saving model to trained_model.h5

Epoch 00008: val_acc did not improve

Epoch 00009: val_acc improved from 0.90205 to 0.90473, saving model to trained_model.h5

Epoch 00010: val_acc improved from 0.90473 to 0.92647, saving model to trained_model.h5

Epoch 00011: val_acc improved from 0.92647 to 0.93867, saving model to trained_model.h5

Epoch 00012: val_acc did not improve

Epoch 00013: val_acc did not improve

Epoch 00014: val_acc did not improve

Epoch 00015: val_acc did not improve

Epoch 00016: val_acc did not improve

Epoch 00017: val_acc did not improve

Epoch 00018: val_acc improved from 0.93867 to 0.94522, saving model to trained_model.h5

Epoch 00019: val_acc did not improve

Epoch 00020: val_acc improved from 0.94522 to 0.95147, saving model to trained_model.h5

Epoch 00021: val_acc improved from 0.95147 to 0.95296, saving model to trained_model.h5

Epoch 00022: val_acc did not improve

Epoch 00023: val_acc did not improve

Epoch 00024: val_acc did not improve

Epoch 00025: val_acc did not improve

  32/3359 [..............................] - ETA: 1:12
  64/3359 [..............................] - ETA: 1:11
  96/3359 [..............................] - ETA: 1:10
 128/3359 [>.............................] - ETA: 1:09
 160/3359 [>.............................] - ETA: 1:09
 192/3359 [>.............................] - ETA: 1:08
 224/3359 [=>............................] - ETA: 1:07
 256/3359 [=>............................] - ETA: 1:07
 288/3359 [=>............................] - ETA: 1:06
 320/3359 [=>............................] - ETA: 1:05
 352/3359 [==>...........................] - ETA: 1:04
 384/3359 [==>...........................] - ETA: 1:04
 416/3359 [==>...........................] - ETA: 1:03
 448/3359 [===>..........................] - ETA: 1:02
 480/3359 [===>..........................] - ETA: 1:02
 512/3359 [===>..........................] - ETA: 1:01
 544/3359 [===>..........................] - ETA: 1:00
 576/3359 [====>.........................] - ETA: 1:00
 608/3359 [====>.........................] - ETA: 59s 
 640/3359 [====>.........................] - ETA: 58s
 672/3359 [=====>........................] - ETA: 58s
 704/3359 [=====>........................] - ETA: 57s
 736/3359 [=====>........................] - ETA: 56s
 768/3359 [=====>........................] - ETA: 56s
 800/3359 [======>.......................] - ETA: 55s
 832/3359 [======>.......................] - ETA: 54s
 864/3359 [======>.......................] - ETA: 54s
 896/3359 [=======>......................] - ETA: 53s
 928/3359 [=======>......................] - ETA: 52s
 960/3359 [=======>......................] - ETA: 51s
 992/3359 [=======>......................] - ETA: 51s
1024/3359 [========>.....................] - ETA: 50s
1056/3359 [========>.....................] - ETA: 49s
1088/3359 [========>.....................] - ETA: 49s
1120/3359 [=========>....................] - ETA: 48s
1152/3359 [=========>....................] - ETA: 47s
1184/3359 [=========>....................] - ETA: 47s
1216/3359 [=========>....................] - ETA: 46s
1248/3359 [==========>...................] - ETA: 45s
1280/3359 [==========>...................] - ETA: 45s
1312/3359 [==========>...................] - ETA: 44s
1344/3359 [===========>..................] - ETA: 43s
1376/3359 [===========>..................] - ETA: 42s
1408/3359 [===========>..................] - ETA: 42s
1440/3359 [===========>..................] - ETA: 41s
1472/3359 [============>.................] - ETA: 40s
1504/3359 [============>.................] - ETA: 40s
1536/3359 [============>.................] - ETA: 39s
1568/3359 [=============>................] - ETA: 38s
1600/3359 [=============>................] - ETA: 38s
1632/3359 [=============>................] - ETA: 37s
1664/3359 [=============>................] - ETA: 36s
1696/3359 [==============>...............] - ETA: 35s
1728/3359 [==============>...............] - ETA: 35s
1760/3359 [==============>...............] - ETA: 34s
1792/3359 [===============>..............] - ETA: 33s
1824/3359 [===============>..............] - ETA: 33s
1856/3359 [===============>..............] - ETA: 32s
1888/3359 [===============>..............] - ETA: 31s
1920/3359 [================>.............] - ETA: 31s
1952/3359 [================>.............] - ETA: 30s
1984/3359 [================>.............] - ETA: 29s
2016/3359 [=================>............] - ETA: 29s
2048/3359 [=================>............] - ETA: 28s
2080/3359 [=================>............] - ETA: 27s
2112/3359 [=================>............] - ETA: 26s
2144/3359 [==================>...........] - ETA: 26s
2176/3359 [==================>...........] - ETA: 25s
2208/3359 [==================>...........] - ETA: 24s
2240/3359 [===================>..........] - ETA: 24s
2272/3359 [===================>..........] - ETA: 23s
2304/3359 [===================>..........] - ETA: 22s
2336/3359 [===================>..........] - ETA: 22s
2368/3359 [====================>.........] - ETA: 21s
2400/3359 [====================>.........] - ETA: 20s
2432/3359 [====================>.........] - ETA: 19s
2464/3359 [=====================>........] - ETA: 19s
2496/3359 [=====================>........] - ETA: 18s
2528/3359 [=====================>........] - ETA: 17s
2560/3359 [=====================>........] - ETA: 17s
2592/3359 [======================>.......] - ETA: 16s
2624/3359 [======================>.......] - ETA: 15s
2656/3359 [======================>.......] - ETA: 15s
2688/3359 [=======================>......] - ETA: 14s
2720/3359 [=======================>......] - ETA: 13s
2752/3359 [=======================>......] - ETA: 13s
2784/3359 [=======================>......] - ETA: 12s
2816/3359 [========================>.....] - ETA: 11s
2848/3359 [========================>.....] - ETA: 11s
2880/3359 [========================>.....] - ETA: 10s
2912/3359 [=========================>....] - ETA: 9s 
2944/3359 [=========================>....] - ETA: 8s
2976/3359 [=========================>....] - ETA: 8s
3008/3359 [=========================>....] - ETA: 7s
3040/3359 [==========================>...] - ETA: 6s
3072/3359 [==========================>...] - ETA: 6s
3104/3359 [==========================>...] - ETA: 5s
3136/3359 [===========================>..] - ETA: 4s
3168/3359 [===========================>..] - ETA: 4s
3200/3359 [===========================>..] - ETA: 3s
3232/3359 [===========================>..] - ETA: 2s
3264/3359 [============================>.] - ETA: 2s
3296/3359 [============================>.] - ETA: 1s
3328/3359 [============================>.] - ETA: 0s
3359/3359 [==============================] - 72s 22ms/step
('Test loss:', 0.18278861831597504)
('Test accuracy:', 0.9529621911460567)
This run of ARABIC ran for 7:20:00 and logs are available locally at: /home/yogse7en/.hyperdash/logs/arabic/arabic_2018-04-06t17-32-43-282814.log
